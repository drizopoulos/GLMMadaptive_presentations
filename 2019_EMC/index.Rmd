---
title: "GLMMadaptive:<br/>Mixed Models for Non-Normal Data in R"
author: "Dimitris Rizopoulos"
date: "February 6"
output:
  ioslides_presentation:
    css: pres.css
    widescreen: yes
    mathjax: default
    logo: emc.png
transition: none
runtime: shiny
---

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script>

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
library("MASS")
library("lme4")
library("glmmTMB")
library("GLMMadaptive")
data("toenail", package = "HSAUR2")
```

# Motivation

## Mixed models

<br/>

- Mixed effects models have numerous applications
    + Longitudinal data
    + Clustered data
    + Multilevel data
    + ...

## The basic idea

<br/>

- We have a grouped outcome ${\color{blue} Y}$
    + measurements in the same group(s) are correlated

<br/>

- Correlations are modeled via random effects ${\color{red} b}$
    + measurements in the same group share the same random effect

## Mathematical definition - 1

- A general definition of mixed models:
$$
\left \{
\begin{array}{ccl}
{\color{blue} Y} \mid {\color{red} b} & \sim & \mathcal F(\theta_y)\\&&\\
{\color{red} b} & \sim & \mathcal N(0, D)\\
\end{array}
\right.
$$
<br/>
    + the distribution $\mathcal F$ depends on the outcome
    + the random effects most often are assumed normally distributed
    + $\theta = (\theta_y^\top, \mbox{vech}(D)^\top)^\top$ are the model parameters

## Mathematical definition - 2

- To estimate mixed models under maximum likelihood we need
the marginal log-likelihood function
$$
\ell(\theta) = \sum_{i = 1}^n \log \int p(y_i \mid b_i; \theta) \, p(b_i; \theta) \; db_i
$$ 
<div style = "padding:120px">
<font color = "red">To estimate mixed models we need to solve the integral</font>
</div>

## Normal vs the rest - 1

- The random effects $b$ are assumed to have a (multivariate) normal distribution
<br/><br/>
- When 
    + the outcome $Y$ also has a normal distribution,
    + the random effects enter linearly in the linear predictor

<div style = "padding:33px">
<font color = "black">the integral can be solved</font> <font color = "purple">*analytically*</font>
<br/><br/>
${\color{blue} \Rightarrow}$ <font color = "blue">Easy to program</font> 
${\color{blue} \Rightarrow}$ <font color = "blue">Stable algorithms available in most software</font>
</div>

## Normal vs the rest - 2

<br/>

- However, in all other cases these integrals cannot be solved analytically

<br/>

<div style = "padding:50px">
${\color{red} \Rightarrow}$ <font color = "red">Much more difficult to program</font>
<br/><br/> 
${\color{red} \Rightarrow}$ <font color = "black">Several solutions available in software,</font> 
<font color = "red">**however, many not optimal!!**</font>
</div>

# Estimation

## How to solve the integrals

- Two general solutions

<br/>

1. Approximation of the integrand
    + make it look like a normal for which we know the solution
    <br/><br/>
2. Approximation of the integral
    + finite sum over a grid


## Popular available options

- Approximation of the integrand
    + Penalized Quasi Likelihood
    + Laplace approximation
    
<br/>

- Approximation of the integral
    + adaptive Gaussian quadrature
    + Monte Carlo (rejection & importance sampling)

## Which to choose

- Penalized Quasi Likelihood: generally not good

<br/>

- Laplace: needs many repeated measurements per subject
    + it does not work well with binary data and Poisson with low counts

<br/>

- Adaptive Gaussian quadrature: <font color = "magenta">*Gold standard*</font>
    + computationally intensive

<br/>

- Monte Carlo: requires fine tuning
    + no clear winner algorithm
    
# What is available in R

## Mixed model packages in R - 1

- `lme4::lmer()`
    + Laplace approximation as default
    + <font color = "red">adaptive Gaussian quadrature only for scalar random effects</font>
<br/><br/>
- `glmmTMB::glmmTMB()` more flexible than **lme4**
    + Laplace approximation
<br/><br/>
- `glmmsr::glmm()`
    + Monte Carlo importance sampling
<br/><br/>
- `MASS::glmmPQL()`
    + PQL based on `nlme::lme()`

## Does it matter? - 1

- The Toenail dataset `data("toenail", package = "HSAUR2")`
    + mixed effects logistic regression
    + PQL vs Laplace vs adaptive Gaussian quadrature

```{r toenail_analysis, message = FALSE}
fm_PQL <- glmmPQL(outcome ~ time * treatment, random = ~ 1 | patientID, 
                  data = toenail, family = binomial())

fm_Laplace <- glmer(outcome ~ time * treatment + (1 | patientID), 
                  data = toenail, family = binomial())

fm_AGQ15 <-  glmer(outcome ~ time * treatment + (1 | patientID), 
                  data = toenail, family = binomial(), nAGQ = 15)
```

## Does it matter? - 2

- The Toenail dataset - results

```{r toenail_results}
cbind(PQL = fixef(fm_PQL), Laplace = fixef(fm_Laplace), AGQ_15 = fixef(fm_AGQ15))
```

## Does it matter? - 3

- The Salamanders dataset `data("Salamanders", package = "glmmTMB")`
    + mixed effects truncated Poisson
    + <font color = "red">(spoiler alert: Code) </font>

```{r Salamanders_analysis}
gm_Laplace <- glmmTMB(count ~ spp + mined + (1 | site), ziformula = ~ spp + mined, 
                      family = truncated_poisson(), data = Salamanders)

gm_AGQ25 <- mixed_model(count ~ spp + mined, random = ~ 1 | site, 
                        zi_fixed = ~ spp + mined, 
                        family = hurdle.poisson(), data = Salamanders, nAGQ = 25)
```

## Does it matter? - 4

- The Salamanders dataset - results

```{r Salamanders_results}
cbind(Laplace = fixef(gm_Laplace)$cond, AGQ_25 = fixef(gm_AGQ25))
```

## Mixed model packages in R - 2

<br/>
<br/>

<div style="float: center; text-align: center; width: 750px; border: 3px solid black">
<br/><br/>
<strong><font size="6" color = "red">Need for adaptive Gaussian quadrature for ${\color{red} > 1}$ random effects</font></strong>
<br/><br/>
</div>

## A new package

<br/>

- **GLMMadaptive** has been written to fill this gap

<br/>

- Principles
    + User-friendly
    + Satisfy the needs of most users
    + Give advanced users the option to extend it
    + Well documented
    
# What GLMMadaptive offers

## Model fitting

- The basic model-fitting function is `GLMMadaptive::mixed_model()`

<br/>

- Required arguments
    + `fixed` a formula for the fixed effects
    + `random` a formula for the random effects
    + `data` a data frame containing the variables to use
    + `family` a family object specifying the model

## Available models: Standard GLMMs

- It fits the most frequently-used GLMMs
    + mixed effects logistic regression `family = binomial()`
    + mixed effects Poisson regression `family = poisson()`

- A basic example:
```r
mixed_model(fixed = y ~ time * group, random = ~ time | id, data = DF,
            family = binomial(), nAGQ = 15)
```

```r
vignette("GLMMadaptive_basics", package = "GLMMadaptive")
```

## Available models: Specialized GLMMs - 1

<br/>

- It fits some non-standard GLMMs
    + negative binomial mixed model `family = negative.binomial()`
    + Student's-t mixed model `family = students.t()`
    + Beta mixed model `family = beta.fam()`

## Available models: Specialized GLMMs - 2

- Zero-inflated mixed models
    + zero-inflated Poisson `family = zi.poisson()`
    + zero-inflated negative binomial `family = zi.negative.binomial()`
<br/><br/>
- Hurdle mixed models
    + hurdle Poisson `family = hurdle.poisson()`
    + hurdle negative binomial `family = hurdle.negative.binomial()`
    + hurdle log-normal `family = hurdle.lognormal()`
    + hurdle Beta `family = hurdle.beta.fam()`

```r
vignette("ZeroInflated_and_TwoPart_Models", package = "GLMMadaptive")
```
    
## User-defined models

<br/>

- The user can define its own mixed model using a user-defined `family` object
    + specify log-density function
    + specify derivatives (optional)
    
```r
vignette("Custom_Models", package = "GLMMadaptive")
```

## What the user needs - 1

- `summary()`: Estimated coefficients, standard errors & p-values

<br/>

- `anova()`: Hypothesis testing
    + Wald tests
    + likelihood ratio tests
    + AIC/BIC

## What the user needs - 2

<br/>

- Effects Plots
    + build-in `effectPlotData()`
    + support for **effects**
    + support for **ggeffects**

```r
vignette("Methods_MixMod", package = "GLMMadaptive")
```
## What the user needs - 3

<br/>

- Goodness of Fit
    + support for **DHARMa**
    + <font color = "red">caveat:</font> MAR missing data

```r
vignette("Goodness_of_Fit", package = "GLMMadaptive")
```

## What the user needs - 4

<br/>

- Multiple comparisons
    + support for **emmeans**
    + support for **multcomp**

```r
vignette("Multiple_Comparisons", package = "GLMMadaptive")
```
## What the user needs - 5

- Predictions via `predict()` method
    + average subject
    + marginal
    + subject-specific
    + dynamic subject-specific
    + confidence & prediction intervals
    + proper scoring rules via `scoring_rules()`

```r
vignette("Methods_MixMod", package = "GLMMadaptive")

vignette("Dynamic_Predictions", package = "GLMMadaptive")
```

## What the user needs - 6

- Methods for standard generics
    + `confint()`, `vcov()` including the sandwich estimator
    + `coef()`, `fixef()`, `ranef()`
    + `logLik()`, `nobs()`
    + `fitted()`, `residuals()`
    + `simulate()`
<br/><br/>
- For developers
    + `model.matrix()`, `model.frame()`
    + `terms()`, `formula()`, `family()`

## A Few extras - 1

<br/>

- Interpretation
    + with nonlinear link functions fixed effects have an interpretation conditional on the random effects [1]
    + <font color = "red">(very) often not what we want</font>
<br/><br/>

<font size = 5>[1] an explanation can be found at: [https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression](https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression)</font>

## A Few extras - 2

<br/>

- Marginalized coefficients
    + Heagerty et al. have proposed marginalized mixed models<br/>
    ${\color{red} \Rightarrow}$ <font color = "red">Computationally intensive to fit</font>
    + [Hedeker et al.](https://dx.doi.org/10.1111/biom.12707) recently proposed an easier alternative solution
    + function `marginal_coefs()` implements Hedeker's et al. solution with standard errors

## A Few extras - 3

- Separation issues
    + in logistic, Poisson and negative binomial data we may encounter (complete) separation [2]
    + `penalized` argument of `mixed_model()` places a Student's t penalty on the fixed effects 
    + the user can control scale (default 1) and df (default 3)
<br/><br/>

<font size = 5>[2] an example at: [https://stats.stackexchange.com/questions/386553/linear-mixed-model-for-placement-of-nuclear-stress-in-10-word-turns](https://stats.stackexchange.com/questions/386553/linear-mixed-model-for-placement-of-nuclear-stress-in-10-word-turns)</font>


## Documentation

<br/>

- Up-to-date help files

<br/>

- Dedicated website: [https://drizopoulos.github.io/GLMMadaptive/](https://drizopoulos.github.io/GLMMadaptive/)
    
# What the future holds...

## Future plans

- Implement nested random effects
    + using **Matrix** sparse matrices classes

<br/>

- More options for the covariance matrix of the random effects
    + auto-regressive
    + compound symmetry

<br/>

- Extra models
    + Conway-Maxwell-Poisson mixed model
    
***

<br/> 
<br/> 

<div align = "center">
<font color = "black" size = "6">**Thank you for your attention!**</font>
</div>
<br/>
<div align = "center">
[http://www.drizopoulos.com/](http://www.drizopoulos.com/)
</div>

<br/> 
<br/>
<br/>

<div align = "center">
<font color = "black" size = "5">**These slides are available at:**</font>
</div>
<div align = "center">
<div align = "center">
[https://drizopoulos.github.io/GLMMadaptive_presentations/](https://drizopoulos.github.io/GLMMadaptive_presentations/)
</div>

